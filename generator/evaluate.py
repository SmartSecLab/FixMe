
# ### 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)
import numpy as np
import pandas as pd
import evaluate
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer

# custom imports
from generator.prompt import zero_prompt

dash_line = '=' * 50
rouge = evaluate.load('rouge')


def show_original_instruct_summary(dataset, tokenizer, original_model, instruct_model, index=200):
    prompt = zero_prompt(dataset, index=index)
    human_baseline_summary = dataset['test'][index]['summary']

    input_ids = tokenizer(prompt, return_tensors="pt").input_ids

    original_model_outputs = original_model.generate(
        input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))
    original_model_text_output = tokenizer.decode(
        original_model_outputs[0], skip_special_tokens=True)

    instruct_model_outputs = instruct_model.generate(
        input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))
    instruct_model_text_output = tokenizer.decode(
        instruct_model_outputs[0], skip_special_tokens=True)

    print(dash_line)
    print(f'BASELINE PATCH:\n{human_baseline_summary}')
    print(dash_line)
    print(f'ORIGINAL MODEL:\n{original_model_text_output}')
    print(dash_line)
    print(f'INSTRUCT MODEL:\n{instruct_model_text_output}')


def evaluate_rouge(results):
    """ Evaluate the summaries generated by the models using the ROUGE metric """
    human_baseline_summaries = results['human_baseline_summaries'].values
    original_model_summaries = results['original_model_summaries'].values
    instruct_model_summaries = results['instruct_model_summaries'].values

    original_model_results = rouge.compute(
        predictions=original_model_summaries,
        references=human_baseline_summaries[0:len(original_model_summaries)],
        use_aggregator=True,
        use_stemmer=True,
    )

    instruct_model_results = rouge.compute(
        predictions=instruct_model_summaries,
        references=human_baseline_summaries[0:len(instruct_model_summaries)],
        use_aggregator=True,
        use_stemmer=True,
    )

    print('ORIGINAL MODEL:')
    print(original_model_results)
    print('INSTRUCT MODEL:')
    print(instruct_model_results)

    print("Absolute percentage improvement of INSTRUCT MODEL over ORIGINAL MODEL")

    improvement = (np.array(list(instruct_model_results.values())) -
                   np.array(list(original_model_results.values())))
    for key, value in zip(instruct_model_results.keys(), improvement):
        print(f'{key}: {value*100:.2f}%')


def generate_summaries(original_model, instruct_model, tokenizer, dialogues, human_baseline_summaries, result_csv):
    """" Generate summaries for a list of dialogues using a model """
    original_model_summaries = []
    instruct_model_summaries = []
    for _, dialogue in enumerate(dialogues):
        prompt = f"""
                    Summarize the following conversation.

                    {dialogue}

                    Summary: """
        input_ids = tokenizer(prompt, return_tensors="pt").input_ids

        original_model_outputs = original_model.generate(
            input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))
        original_model_text_output = tokenizer.decode(
            original_model_outputs[0], skip_special_tokens=True)

        original_model_summaries.append(original_model_text_output)

        instruct_model_outputs = instruct_model.generate(
            input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))
        instruct_model_text_output = tokenizer.decode(
            instruct_model_outputs[0], skip_special_tokens=True)

        instruct_model_summaries.append(instruct_model_text_output)

    zipped_summaries = list(zip(human_baseline_summaries,
                            original_model_summaries, instruct_model_summaries))

    df = pd.DataFrame(zipped_summaries, columns=[
        'human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])
    df.to_csv(result_csv, index=False)
    print(dash_line)
    print(f"Results of vul-fix-training saved to {result_csv}")
    print(dash_line)
    print("Sample of the results:")
    print(df.head())
    print(dash_line)
    return df
