# # Generative AI Use Case: Patches Generation

Welcome to the practical side of this course. In this lab you will do the dialogue summarization task using generative AI. You will explore how the input text affects the output of the model, and perform prompt engineering to direct it towards the task you need. By comparing zero shot, one shot, and few shot inferences, you will take the first step towards prompt engineering and see how it can enhance the generative output of Large Language Models.

# Table of Contents

- [1 - Set up Kernel and Required Dependencies]( # 1)

- [2 - Summarize Dialogue without Prompt Engineering]( # 2)

- [3 - Summarize Dialogue with an Instruction Prompt]( # 3)

- [3.1 - Zero Shot Inference with an Instruction Prompt]( # 3.1)

- [3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5]( # 3.2)

- [4 - Summarize Dialogue with One Shot and Few Shot Inference]( # 4)

- [4.1 - One Shot Inference]( # 4.1)

- [4.2 - Few Shot Inference]( # 4.2)

- [5 - Generative Configuration Parameters for Inference]( # 5)

# 1 - Set up Kernel and Required Dependencies

First, check that the correct kernel is chosen.

You can click on that(top right of the screen) to see and check the details of the image, kernel, and instance type.

Now install the required packages to use PyTorch and Hugging Face transformers and datasets.

-
